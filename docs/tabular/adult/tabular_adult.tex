\documentclass[11pt]{article}

% -------------------------------------------------
% Packages
% -------------------------------------------------
\usepackage[margin=1in]{geometry}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{mathtools}
\usepackage{bm}
\usepackage{siunitx}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{hyperref}
\hypersetup{colorlinks=true, linkcolor=blue, urlcolor=blue, citecolor=blue}

% -------------------------------------------------
% Macros
% -------------------------------------------------
\newcommand{\GT}{\textsc{GT}}     % Ground Truth
\newcommand{\SIM}{\textsc{SIM}}   % Simulated
\newcommand{\SYN}{\textsc{SYN}}   % Synthetic
\newcommand{\Real}{\mathbb{R}}
\newcommand{\Prb}{\mathbb{P}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\KL}{\mathrm{KL}}
\newcommand{\JS}{\mathrm{JS}}
\newcommand{\MMD}{\mathrm{MMD}}
\newcommand{\1}{\mathbf{1}}
\newcommand{\norm}[1]{\left\lVert #1 \right\rVert}
\newcommand{\RBF}{\mathrm{RBF}}

% -------------------------------------------------
% Title
% -------------------------------------------------
\title{Adult Tabular Experiment: Information-Theoretic Fidelity Evaluation\\
\large Ground Truth vs. Simulated vs. Synthetic (SDV CTGAN/TVAE)}
% \author{Independent Study: Synthetic Data Fidelity}
\date{\today}

\begin{document}
\maketitle

\section{Overview}

This experiment quantifies the \emph{information fidelity} of synthetic and simulated tabular data against a ground-truth reference, using the UCI Adult/Census Income dataset. We evaluate three data sources for the same phenomenon:
\begin{enumerate}[itemsep=2pt, topsep=2pt]
  \item \GT: ground-truth rows drawn from the real dataset (held-out split).
  \item \SIM: simulated rows generated from feature-wise fitted distributions.
  \item \SYN: synthetic rows generated by a learned model (SDV's CTGAN or TVAE) fit on the training split of the real dataset.
\end{enumerate}

All sources are evaluated in a \emph{common numeric representation}: continuous features are standardized, and categorical features are one-hot encoded. Metrics include per-feature Jensen--Shannon (JS) divergence for continuous marginals, and global distributional tests: Maximum Mean Discrepancy (MMD) with an RBF kernel and a Classifier Two-Sample Test (C2ST) AUC.

\section{Repository Layout and Execution}

\paragraph{Key paths}
\begin{verbatim}
common/                       # shared utilities (I/O, metrics, viz, seeding)
experiments/adult_tabular/
  run.py                      # CLI entry point
  data.py                     # download/clean/split + encoders (scaler, OHE)
  simulate.py                 # per-feature fitting + (optional) Gaussian copula
  synth_sdv.py                # SDV CTGAN/TVAE training + sampling
  evaluate.py                 # JS, MMD, C2ST + figures
  figures/                    # output histograms (created at runtime)
  data_cache/                 # dataset cache (created at runtime)
  results.json                # machine-readable results for a run
\end{verbatim}

\paragraph{How to run (from repo root)}
\begin{verbatim}
python -m experiments.adult_tabular.run \
  --seed 42 \
  --n_eval 5000 \
  --sim_mode gaussian_copula \
  --synth ctgan \
  --epochs 300 \
  --batch_size 500 \
  --pac 10 \
  --out results_ctgan.json
\end{verbatim}
For TVAE, use \verb|--synth tvae| (the \verb|--pac| flag is ignored).

\section{Data, Splits, and Preprocessing}

Let $X \in \Real^{n \times d}$ denote features and $Y \in \{0,1\}$ the \texttt{income} label. The pipeline:
\begin{enumerate}[itemsep=2pt, topsep=2pt]
  \item Download and clean the Adult dataset; drop rows with missing values.
  \item Split into train/eval (e.g., 75/25, stratified by $Y$).
  \item Fit preprocessing on the \emph{train} split only:
    \begin{itemize}[itemsep=1pt]
      \item StandardScaler on continuous columns: $x \mapsto (x-\mu)/\sigma$.
      \item One-Hot Encoder on categorical columns 
      % (handle-unknown=\texttt{ignore}).
    \end{itemize}
  \item Transform the \emph{eval} split using the fitted transformer; this provides the \GT\ reference sample for metrics.
\end{enumerate}
We evaluate only in the standardized + one-hot space; labels are not used by the core metrics.

\section{Simulated Data (\SIM)}

\subsection{Per-Feature Fitting}
For each raw (unencoded) feature, we detect a plausible family and estimate parameters:
\begin{itemize}[itemsep=2pt]
  \item \textbf{Binary}: Bernoulli$(p)$ via $\hat p = \frac{1}{n}\sum \1\{x_i=1\}$.
  \item \textbf{Categorical}: empirical multinomial over observed categories.
  \item \textbf{Counts} (nonnegative integers): Poisson$(\lambda)$ if $\widehat{\Var}\!\approx\!\hat\lambda$, else Negative Binomial.
  \item \textbf{Continuous}: AIC-based model selection among
        Normal, Lognormal, Gamma, Exponential, Student-$t$
        % , and \emph{scaled Beta} if the feature is bounded. 
        Parameters are fit by maximum likelihood.
\end{itemize}
% This yields fitted marginals $\{\widehat{F}_j\}_{j=1}^d$.

% \subsection{Dependence via a Gaussian Copula (optional)}
% To preserve cross-feature dependence among continuous features:
% \begin{enumerate}[itemsep=2pt]
%   \item Probability integral transform (PIT): $u_{ij}=\widehat{F}_j(x_{ij})$.
%   \item Normal scores: $z_{ij} = \Phi^{-1}(u_{ij})$ where $\Phi$ is the standard normal CDF.
%   \item Fit correlation $\widehat{\Sigma}$ on $Z$; sample $Z^{\star}\sim \mathcal{N}(0,\widehat{\Sigma})$.
%   \item Map back: $u^{\star}_{\cdot j}=\Phi(z^{\star}_{\cdot j})$, then $x^{\star}_{\cdot j}=\widehat{F}_j^{-1}(u^{\star}_{\cdot j})$.
% \end{enumerate}
% Discrete features (categorical, binary, counts) are sampled independently from their fitted marginals. The resulting raw \SIM\ frame is transformed by the same scaler/OHE to the evaluation space.

\section{Synthetic Data (\SYN)}

We train a single-table synthesizer on the raw train split:
\begin{itemize}[itemsep=2pt]
  \item \textbf{CTGAN}: Conditional GAN for tabular data with mode collapse mitigation. Important hyperparameters include epochs, batch size, and the ``pack'' size (\emph{pac}), with the constraint that \texttt{batch\_size \% pac = 0}.
  \item \textbf{TVAE}: Variational autoencoder variant for tabular synthesis.
\end{itemize}
% Generated rows are then passed through the same scaler/OHE to align with \GT\ and \SIM\ for evaluation.

\section{Evaluation Metrics}

Let $P,Q$ denote distributions over a common $D$-dimensional numeric space (standardized+one-hot). Let $\{x_i\}_{i=1}^n \sim P$ and $\{y_j\}_{j=1}^m \sim Q$ be i.i.d.\ samples.

\subsection{Per-Feature Jensen--Shannon Divergence (Continuous Marginals)}
For a single continuous feature $X$ with histograms $p$ and $q$ (using the same bins and ranges), define the JS divergence
\begin{align}
  \JS(p\Vert q)
  \;=\;
  \tfrac{1}{2}\,\KL\!\left(p \,\middle\Vert\, \tfrac{p+q}{2}\right)
  \;+\;
  \tfrac{1}{2}\,\KL\!\left(q \,\middle\Vert\, \tfrac{p+q}{2}\right),
\end{align}
where $\KL(p\Vert q)=\sum_b p_b \log\frac{p_b}{q_b}$ is the discrete (binned) KL. We report \emph{per-feature} JS for the continuous columns, comparing pairs $(\GT,\SIM)$, $(\GT,\SYN)$, and $(\SIM,\SYN)$. Lower is better, and $\JS=0$ iff histograms match exactly.%
\footnote{Because JS here is computed from histograms, values depend on the binning scheme. We use a fixed number of bins and shared ranges for fairness.}

\subsection{Maximum Mean Discrepancy (MMD) with RBF Kernel}
Let $k(x,y)$ be a positive definite kernel. The squared MMD between $P$ and $Q$ in the RKHS $\mathcal{H}$ induced by $k$ is
\begin{align}
  \MMD^2(P,Q)
  \;=\;
  \norm{ \mu_P - \mu_Q }_{\mathcal{H}}^2
  \;=\;
  \E_{x,x'}[k(x,x')] + \E_{y,y'}[k(y,y')] - 2\,\E_{x,y}[k(x,y)].
\end{align}
With samples, an unbiased estimator is
\begin{align}
  \widehat{\MMD}^2
  \;=\;
  \frac{1}{n(n-1)}\!\!\sum_{i\neq i'} \!k(x_i, x_{i'})
  \;+\;
  \frac{1}{m(m-1)}\!\!\sum_{j\neq j'} \!k(y_j, y_{j'})
  \;-\;
  \frac{2}{nm}\sum_{i,j} k(x_i, y_j).
\end{align}
We use the RBF kernel $k(x,y)=\exp(-\gamma \norm{x-y}^2)$ with $\gamma=\frac{1}{2\sigma^2}$ and $\sigma$ chosen by the median heuristic on a subsample. Lower $\MMD$ indicates closer joint distributions. We report MMD for $(\GT,\SYN)$, $(\GT,\SIM)$, and $(\SIM,\SYN)$.

\subsection{Classifier Two-Sample Test (C2ST) AUC}
The C2ST trains a binary classifier to distinguish $P$-samples from $Q$-samples. Let $f:\Real^D\to[0,1]$ be a probabilistic classifier trained on labeled examples 
$\{(x_i,0)\}_{i=1}^n\cup\{(y_j,1)\}_{j=1}^m$. A strong classifier suggests a detectable difference between $P$ and $Q$. We report the ROC--AUC on the combined sample:
\begin{align}
  \mathrm{AUC} \;=\; \Prb\big( f(Y^+) > f(X^-) \big),
\end{align}
where $Y^+$ is a positive (from $Q$) and $X^-$ is a negative (from $P$) draw. An AUC of $0.5$ indicates indistinguishability by the classifier (chance), while $1.0$ indicates perfect separability. We use logistic regression (linear decision boundary) for stability and interpretability.

\paragraph{Interpretation summary}
\begin{itemize}[itemsep=2pt]
  \item \textbf{Per-feature JS (continuous)}: marginal fidelity; sensitive to univariate shifts/tails.
  \item \textbf{MMD (RBF)}: global multivariate discrepancy; captures joint geometry across all features.
  \item \textbf{C2ST AUC}: discriminability; how easy it is to tell the two samples apart.
\end{itemize}
Combining these provides complementary views: JS for marginal alignment, MMD for joint structure, and C2ST for practical detectability.

\section{Outputs and Artifact Schema}

Each run writes:
\begin{itemize}[itemsep=2pt]
  \item \textbf{Figures}: histograms for each continuous feature comparing \GT/\SIM/\SYN.
  \item \textbf{JSON}: a single machine-readable \verb|results.json| containing provenance and metrics.
\end{itemize}

\paragraph{JSON (abridged shape)}
\begin{verbatim}
{
  "experiment": { "name": "adult_tabular", "timestamp": "...", "seed": 42 },
  "data": {
    "ground_truth": { "type": "external", "source": "...", "n_train": ..., ... },
    "simulated":    { "generator": "per_feature_gaussian_copula", "n": ... },
    "synthetic":    { "library": "SDV", "model": "CTGAN" | "TVAE", "train": {...} }
  },
  "metrics": {
    "continuous_js": { "<feature_name>": { "gt_vs_sim": ..., "gt_vs_syn": ..., ... }, ... },
    "global": {
      "mmd_rbf_gt_syn": ..., "mmd_rbf_gt_sim": ..., "mmd_rbf_sim_syn": ...,
      "c2st_auc_gt_syn": ..., "c2st_auc_gt_sim": ..., "c2st_auc_sim_syn": ...
    }
  },
  "figures": ["hist_age.png", "hist_fnlwgt.png", ...],
  "notes": "...",
  "versions": { "python": "...", "platform": "..." }
}
\end{verbatim}

\section{Reproducibility and CLI Parameters}

\paragraph{Seeds} A single \verb|--seed| is propagated to NumPy/PyTorch (where applicable) and used for simulators and sampling.

\paragraph{Key flags}
\begin{itemize}[itemsep=2pt]
  \item \verb|--sim_mode| $\in \{\mathtt{independent}, \mathtt{gaussian\_copula} \}$ controls dependence modeling in \SIM.
  
  \item \verb|--synth| $\in \{\texttt{ctgan}, \texttt{tvae}\}$ chooses the SDV model.
  
  \item \verb|--epochs|, \verb|--batch_size| control training; CTGAN also uses \verb|--pac| and requires \verb|batch_size \% pac = 0|.
  \item \verb|--n_eval| sets the sample size for \SIM/\SYN  and the reference size from \GT\ (size-matched).
\end{itemize}

% \section{Limitations and Extensions}

% \begin{itemize}[itemsep=2pt]
%   \item \textbf{Histogram JS}: depends on binning; consider adaptive binning or kernel density for robustness.
%   \item \textbf{Single-kernel MMD}: sensitivity depends on kernel bandwidth; multiple kernels or Kernel Two-Sample Tests with bandwidth sweeps can increase power.
%   \item \textbf{Linear C2ST}: logistic regression may under-detect differences that require nonlinear boundaries; a shallow MLP variant can be added for sensitivity analysis, with care to avoid overfitting.
%   \item \textbf{Dependence in \SIM}: Gaussian copula preserves correlation among continuous features but not categorical--continuous dependence; extensions include vine copulas or conditional simulators.
%   \item \textbf{Label-conditioned fidelity}: optional utilities can train a downstream classifier (e.g., income) on one source and test on another to quantify ``utility fidelity.'' This is not part of the default metrics but is straightforward to add.
% \end{itemize}

\section{Practical Interpretation Guide}

When comparing $(\GT,\SYN)$ and $(\GT,\SIM)$:
\begin{itemize}[itemsep=2pt]
  \item If \textbf{JS} is low across most continuous features, marginal distributions are well matched.
  \item If \textbf{MMD} is low while JS is low, the joint distribution is also close.
  \item If \textbf{C2ST AUC} is near $0.5$, a linear classifier cannot easily distinguish the samples; large AUC indicates detectable differences.
  % \item Compare \SYN\ vs.\ \SIM: if \SYN\ consistently achieves lower MMD and lower C2ST AUC than \SIM, the learned generator is capturing joint structure beyond feature-wise marginals.
\end{itemize}

% \section*{Appendix: Metric Details}

% \paragraph{Discrete JS via histograms}
% Let $\{I_b\}_{b=1}^B$ be fixed bins and $p_b = \frac{1}{n}\sum_{i=1}^n \1\{x_i\in I_b\}$, $q_b$ analogously. With $m_b=\tfrac{1}{2}(p_b+q_b)$:
% \[
% \JS(p\Vert q) = \tfrac{1}{2}\sum_{b=1}^B p_b \log\frac{p_b}{m_b}
%               + \tfrac{1}{2}\sum_{b=1}^B q_b \log\frac{q_b}{m_b}.
% \]
% Small constants are applied to avoid $\log 0$ and renormalize.

% \paragraph{RBF kernel bandwidth}
% We set $\sigma$ by the median pairwise distance among a random subset of samples; $\gamma=1/(2\sigma^2)$.

% \paragraph{C2ST training}
% We concatenate samples with labels $\{0,1\}$ and fit logistic regression. AUC is computed on the \emph{combined} data for a high-signal test.

\end{document}
